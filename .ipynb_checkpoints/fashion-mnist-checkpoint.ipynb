{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "## Recent architectures\n",
    "\n",
    "![Idea](images/Cover.png)\n",
    "\n",
    "### Keep it simple and clean\n",
    "\n",
    "![LeNet famous network](images/LeNet.png)\n",
    "![VGG - 2013](images/deep_CNN.jpg)\n",
    "\n",
    "### We need two GPU that works separetely, still simple\n",
    "\n",
    "![AlexNet - 2013](images/AlexNet.png)\n",
    "\n",
    "### Google says, f**k simplicity\n",
    "\n",
    "![Idea](images/GoogleNet5.png)\n",
    "![GoogLeNet - 2014](images/GoogleNet.gif)\n",
    "\n",
    "### Microsoft answer, Who have it longer?\n",
    "\n",
    "![ResNet - 2015](images/ResNet.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorization examples\n",
    "\n",
    "Fashion MNIST is a drop-in replacement for the very well known, machine learning hello world, MNIST dataset. It has same number of training and test examples and the images have the same 28x28 size and there are a total of 10 classes/labels, you can read more about the dataset here : [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "\n",
    "In this post we will be trying out different models and compare their results:\n",
    "\n",
    "## List of models\n",
    "\n",
    "1. 2 Layer Neural Netwoek\n",
    "2. CNN with 1 Convolutional Layer\n",
    "3. CNN with 3 Convolutional Layers\n",
    "4. VGG Like Model\n",
    "5. VGG Like Model With Batchnorm\n",
    "\n",
    "\n",
    "## Approach\n",
    "\n",
    "I split the original training data into 80% training and 20% validation. This helps to see weather we're over-fitting on the training data and weather we should lower the learning rate and train for more epochs if validation accuracy is higher than training accuracy or stop over-training if training accuracy shift higher than the validation.\n",
    "\n",
    "To be consistent here, all the models are initially trained for 10 epochs and another 10 epochs with a lower learning late. After the initial 20 epochs, I added data augmentation, which generates new training samples by rotating, shifting and zooming on the training samples, and trained for another 50 epochs.\n",
    "\n",
    "Also, to avoid hot encoding the labels, I decided to use `sparse_categorical_crossentropy` when compiling the models.\n",
    "\n",
    "## Observations\n",
    "All the models achieved a higher accuracy after using data augmentation. Almost always use data augmentation!!\n",
    "\n",
    "VGG Like Model With Batchnorm performed the best and achieved a accuarcy of 94% using data augmentation.\n",
    "\n",
    "\n",
    "## Fun Fact\n",
    "\n",
    "If you uncomment the code in **Drop-in Replacement you said?** section, you'll be able to run all the models on MNIST instead of Fashion-MNIST.\n",
    "It is much easier to get +99.5% results on MNIST. However, as you can see by running the models on both datasets, it gets relatively harder to squeeze accuracy on the Fashion-MNIST dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(12345)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Load Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz\n",
      "Downloading data from https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz\n",
      "Downloading data from https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Downloading data from https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "train_images_path = keras.utils.get_file('train-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz')\n",
    "train_labels_path = keras.utils.get_file('train-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz')\n",
    "test_images_path = keras.utils.get_file('t10k-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = keras.utils.get_file('t10k-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(images_path, labels_path):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_orig, y_train_orig = load_mnist(train_images_path, train_labels_path)\n",
    "X_test, y_test = load_mnist(test_images_path, test_labels_path)\n",
    "X_train_orig = X_train_orig.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_orig /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop-in Replacement you said?\n",
    "As I said at the beginning, fashion MNIST is drop-in replacement for MNINT. In case you want to run all these models on MNIST and compare the results. Uncomment the next section and everything should work automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist\n",
    "# (X_train_orig, y_train_orig), (X_test, y_test) = mnist.load_data()\n",
    "# X_train_orig = X_train_orig.reshape(60000, 784)\n",
    "# X_test = X_test.reshape(10000, 784)\n",
    "# X_train_orig = X_train_orig.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "# X_train_orig /= 255\n",
    "# X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_orig.shape)\n",
    "print(y_train_orig.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_orig, y_train_orig, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(48000,)\n",
      "(12000, 784)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdbc1f15550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n98xOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdbe01b1f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1, :].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, input_shape=(784,), activation='relu'),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 468,874.0\n",
      "Trainable params: 468,874\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.6287 - acc: 0.7819 - val_loss: 0.4195 - val_acc: 0.8572\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.4128 - acc: 0.8553 - val_loss: 0.3899 - val_acc: 0.8665\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.3719 - acc: 0.8670 - val_loss: 0.3549 - val_acc: 0.8808\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.3386 - acc: 0.8783 - val_loss: 0.3286 - val_acc: 0.8864\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.3167 - acc: 0.8866 - val_loss: 0.3122 - val_acc: 0.8894\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2975 - acc: 0.8926 - val_loss: 0.3272 - val_acc: 0.8846\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2860 - acc: 0.8954 - val_loss: 0.3130 - val_acc: 0.8907\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2725 - acc: 0.9001 - val_loss: 0.2916 - val_acc: 0.8972\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2600 - acc: 0.9050 - val_loss: 0.3046 - val_acc: 0.8919\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2496 - acc: 0.9074 - val_loss: 0.2873 - val_acc: 0.89770.907\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2393 - acc: 0.9112 - val_loss: 0.2910 - val_acc: 0.8962\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2265 - acc: 0.9165 - val_loss: 0.3008 - val_acc: 0.8969\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2251 - acc: 0.9166 - val_loss: 0.2886 - val_acc: 0.8962\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2142 - acc: 0.9208 - val_loss: 0.3038 - val_acc: 0.8942\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2021 - acc: 0.9250 - val_loss: 0.2831 - val_acc: 0.9011\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1981 - acc: 0.9260 - val_loss: 0.2793 - val_acc: 0.9018\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1876 - acc: 0.9314 - val_loss: 0.2878 - val_acc: 0.8994\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1865 - acc: 0.9305 - val_loss: 0.2865 - val_acc: 0.9001\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1817 - acc: 0.9323 - val_loss: 0.2860 - val_acc: 0.9011\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1710 - acc: 0.9363 - val_loss: 0.2928 - val_acc: 0.9033\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3474293149590492\n",
      "Test accuracy: 0.8858\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with 1 Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1 = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962.0\n",
      "Trainable params: 693,962.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 17s - loss: 0.6536 - acc: 0.7764 - val_loss: 0.4224 - val_acc: 0.8552\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 17s - loss: 0.4005 - acc: 0.8596 - val_loss: 0.3476 - val_acc: 0.8806\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.3475 - acc: 0.8772 - val_loss: 0.3211 - val_acc: 0.8892\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 19s - loss: 0.3233 - acc: 0.8843 - val_loss: 0.2995 - val_acc: 0.8959\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 16s - loss: 0.2997 - acc: 0.8940 - val_loss: 0.2794 - val_acc: 0.9042\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 19s - loss: 0.2864 - acc: 0.8978 - val_loss: 0.2787 - val_acc: 0.9020\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 17s - loss: 0.2724 - acc: 0.9032 - val_loss: 0.2712 - val_acc: 0.9057\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 18s - loss: 0.2657 - acc: 0.9036 - val_loss: 0.2532 - val_acc: 0.9100\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 18s - loss: 0.2536 - acc: 0.9080 - val_loss: 0.2543 - val_acc: 0.9058\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 17s - loss: 0.2486 - acc: 0.9097 - val_loss: 0.2824 - val_acc: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdb98f93668>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 19s - loss: 0.2363 - acc: 0.9138 - val_loss: 0.2463 - val_acc: 0.9132\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 19s - loss: 0.2258 - acc: 0.9184 - val_loss: 0.2446 - val_acc: 0.9139\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 17s - loss: 0.2212 - acc: 0.9193 - val_loss: 0.2372 - val_acc: 0.9168\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 18s - loss: 0.2111 - acc: 0.9228 - val_loss: 0.2362 - val_acc: 0.9164\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 18s - loss: 0.2073 - acc: 0.9235 - val_loss: 0.2264 - val_acc: 0.9192\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 18s - loss: 0.1975 - acc: 0.9274 - val_loss: 0.2255 - val_acc: 0.9220\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 21s - loss: 0.1921 - acc: 0.9298 - val_loss: 0.2332 - val_acc: 0.9152\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 18s - loss: 0.1862 - acc: 0.9311 - val_loss: 0.2256 - val_acc: 0.9201\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 21s - loss: 0.1814 - acc: 0.9345 - val_loss: 0.2242 - val_acc: 0.9223\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 21s - loss: 0.1747 - acc: 0.9359 - val_loss: 0.2185 - val_acc: 0.9240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdb98fec668>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2516407194644213\n",
      "Test accuracy: 0.912\n"
     ]
    }
   ],
   "source": [
    "score = cnn1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/93 [=========================>....] - ETA: 2s - loss: 0.3995 - acc: 0.8489"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-85bf3d7fe917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m cnn1.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=10, \n\u001b[0;32m----> 2\u001b[0;31m                     validation_data=val_batches, validation_steps=12000//batch_size)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ml-intro/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-intro/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-intro/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-intro/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1875\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-intro/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-intro/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-intro/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-intro/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-intro/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/ml-intro/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-intro/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn1.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=10, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cnn1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNN with 3 Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2 = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cnn2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn2.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cnn2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNN with 4 Convolutional Layers and Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3 = Sequential([\n",
    "    Lambda(norm_input, input_shape=(28,28, 1)),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu'),    \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),    \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    \n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),    \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cnn3.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn3.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cnn3.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VGG Like Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn4 = Sequential([\n",
    "    Lambda(norm_input, input_shape=(28,28, 1)),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    \n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),    \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    \n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),    \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    \n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn4.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn4.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn4.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn4.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cnn4.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn4.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cnn4.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VGG Like Model With Batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn5 = Sequential([\n",
    "    Lambda(norm_input, input_shape=(28,28, 1)),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),    \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),    \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn5.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn5.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn5.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn5.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cnn5.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn5.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cnn5.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Intro",
   "language": "python",
   "name": "ml-intro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
